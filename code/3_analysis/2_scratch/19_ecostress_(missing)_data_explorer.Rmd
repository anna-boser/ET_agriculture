---
title: "ecostress_data_explorer"
author: "Anna Boser"
date: "12/22/2021"
output: html_document
---

New goal: 
1. Write a script that resamples, saves, and adds to a CSV for (1) ag and (2) natural all ET and uncertainty measures one at a time, deleting them as you go.  Also it periodically saves the csv just in case it blows up because itâ€™s too big
    1. Function for each date
        1. Read in ET and ETuncert
        2. Resample both
        3. Mask both to (1) ag and (2) natural
        4. Add to the two csvs 
        5. Delete everything except the csvs
        6. Every 50 or so files save the csv


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(here)
library(raster)
library(data.table)
library(dplyr)
library(ggplot2)
```

```{r}
# get the ET file names
files <- list.files(path = here("data", "raw", "ECOSTRESS"), full.names = TRUE)

# empty consistent grid
CA_grid <- raster(here("data", "intermediate", "CA_grid.tif"))

# ag and natural land rasters
ag <- raster(here("data", "intermediate", "agriculture", "ag_indicator.tif"))
natural <- raster(here("data", "intermediate", "counterf", "counterf_indicator.tif"))
pixels_of_intrest <- ag|natural

# full, time invariant grid
full <- fread(here("data", "for_analysis", "full_grid_time_invariant.csv"))

# remove entries that are neither ag nor natural
full <- full[agriculture == 1|counterfactual == 1]
# remove the entries that nave na slope etc becasue that just means they're not in California
full <- full[aspect > -20]
```

```{r}
for (i in 1:26){
  print(plot(raster(files[i])))
}
```

```{r}
# get the different image timestamps
timestamps <- str_extract(files, regex('(?<=_doy)[0-9]*(?=_aid0001.tif)'))
unique_timestamps <- unique(timestamps)
names(timestamps) <- files
```

```{r}
# create a dataset for each timestamp
make_dataset <- function(timestamp){
  
  print(paste("New timestamp:", timestamp))
  
  timestamp_files <- names(timestamps[timestamps == timestamp])
  
  # read in rasters, resample to CA_grid, and turn into a rasterbrick
  read_and_rename <- function(file){
    raster <- raster(file)
    names(raster) <- str_extract(names(raster), regex('(?<=_PT_JPL_)[A-z_]*(?=_doy)'))
    raster <- raster(file) %>% resample(CA_grid, method = "bilinear")
    return(raster)
  }
  ECO_brick <- brick(lapply(timestamp_files, read_and_rename))
  
  # mask out non ag or natural
  

  # convert rasters to dataframe rows
  dataset <- cbind(as.data.frame(ECO_brick, xy = TRUE), as.data.frame(landcover, xy = FALSE))
  
  # add date labels
  dataset$date <- as.character(as.Date(timestamp, "%Y%j%H%M%S"))
  dataset$hhmmss <- substring(timestamp, 8)
  dataset$year <- year(as.Date(timestamp, "%Y%j%H%M%S"))
  
  #turn into data table for faster rbinding
  dataset <- as.data.table(dataset)

  return(dataset)
}
```


```{r}
soil <- raster(here("data/intermediate/CA_storie/CA_storie.tif"))
```


