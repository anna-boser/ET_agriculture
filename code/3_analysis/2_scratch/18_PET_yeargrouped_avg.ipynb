{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d95d69aa-31a6-43c3-bef1-0ab62bac43fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script takes the bricked, resampled output of 6_PET.R and resamples it temporally to aggregate to necessary timesteps. \n",
    "# Anna Boser Nov 5, 2021\n",
    "\n",
    "from pyprojroot import here\n",
    "import rasterio\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e22e85c5-fcf3-424d-bef4-6079b7f4cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = rasterio.open(here(\"./data/intermediate/PET/PETbrick_OGres.tif\")) # NA values are -3.4e+38\n",
    "array = np.array(img.read())\n",
    "\n",
    "# get a list of the start indices and end indices of each of your time intervals\n",
    "\n",
    "# these are the dates of the images (bands) in order\n",
    "base = datetime.date(day = 1, month = 1, year = 2019) # start Jan 1 2019\n",
    "date_list = [base + datetime.timedelta(days=x) for x in range(img.count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9703029f-3f36-4b93-8644-911abaa682eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the time intervals I want go back in time to previous years so I need to reshuffle the datasets a bit into their respective years and put jan1-14 at the end\n",
    "# first break up by year\n",
    "\n",
    "imgs_2019 = array[[d.year==2019 for d in date_list]]\n",
    "imgs_2020 = array[[d.year==2020 for d in date_list]]\n",
    "\n",
    "date_array = np.array(date_list)\n",
    "dates_2019 = date_array[[d.year==2019 for d in date_list]]\n",
    "dates_2020 = date_array[[d.year==2020 for d in date_list]]\n",
    "\n",
    "# move anything from January 1 to 14 to after\n",
    "# imgs_2019 = np.concatenate([imgs_2019[14:], imgs_2019[:14]])\n",
    "# imgs_2020 = np.concatenate([imgs_2020[14:], imgs_2020[:14]])\n",
    "\n",
    "imgs_2019 = np.concatenate([imgs_2019[[d >= datetime.date(day = 15, month = 1, year = 2019) for d in dates_2019]], imgs_2019[[d < datetime.date(day = 15, month = 1, year = 2019) for d in dates_2019]]])\n",
    "imgs_2020 = np.concatenate([imgs_2020[[d >= datetime.date(day = 15, month = 1, year = 2020) for d in dates_2020]], imgs_2020[[d < datetime.date(day = 15, month = 1, year = 2020) for d in dates_2020]]])\n",
    "\n",
    "dates_2019 = np.concatenate([dates_2019[[d >= datetime.date(day = 15, month = 1, year = 2019) for d in dates_2019]], dates_2019[[d < datetime.date(day = 15, month = 1, year = 2019) for d in dates_2019]]])\n",
    "dates_2020 = np.concatenate([dates_2020[[d >= datetime.date(day = 15, month = 1, year = 2020) for d in dates_2020]], dates_2020[[d < datetime.date(day = 15, month = 1, year = 2020) for d in dates_2020]]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "014f3d62-f470-4ed8-906f-011d31e9a41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 95, 103)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I am going to mess up the dates for convenience by shifting the beginning of 2019 to be the beginning of 2020 and the beginning of 2020 to be the biginning of 2021 \n",
    "# just for convenience\n",
    "array = np.stack([imgs_2019, imgs_2020])\n",
    "\n",
    "base = datetime.date(day = 15, month = 1, year = 2019)\n",
    "fakedates = [base + datetime.timedelta(days=x) for x in range(img.count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecb9f401-7c78-4e31-a89f-c53fda5ab153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the start dates of the wanted time intervals\n",
    "date_starts_2019 = [datetime.date(day = 15, month = m, year = 2019) for m in [1,3,5,7,9,11]]\n",
    "del date_starts_2019[1]\n",
    "date_starts_2020 = [datetime.date(day = 15, month = m, year = 2020) for m in [1,3,5,7,9,11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f389096-56dd-44e0-bad6-092147aeee61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2019, 1, 15),\n",
       " datetime.date(2019, 3, 15),\n",
       " datetime.date(2019, 5, 15),\n",
       " datetime.date(2019, 7, 15),\n",
       " datetime.date(2019, 9, 15),\n",
       " datetime.date(2019, 11, 15)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523dd690-944d-40ee-97b4-c83f9558c750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a31f161-4d49-4b1d-80d4-0d8140442470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# write date_starts so that we have a metadata record of dates\n",
    "with open(here(\"./data/intermediate/start_dates.pkl\"), 'wb') as f:\n",
    "    pickle.dump(date_starts, f)\n",
    "\n",
    "# index of image on or nearest after start date\n",
    "start_index = [date_list.index(min([i for i in date_list if i >= date_start], key=lambda x:x-date_start)) + 1 for date_start in date_starts] # plus one since bands are 1 indexed\n",
    "\n",
    "# index of image on or nearest previous to start date + 61 days (this is for a non-inclusive index range so this date will be the first one not to be included in a subset)\n",
    "end_index = [date_list.index(min([i for i in date_list if i <= date_start + datetime.timedelta(days=61)], key=lambda x:date_start+datetime.timedelta(days=61)-x)) + 1 for date_start in date_starts] # plus one since bands are 1 indexed\n",
    "\n",
    "newarray = np.stack([array[start_index[i]:end_index[i]].mean(axis = 0) for i in range(0,len(start_index))], axis=0)\n",
    "\n",
    "metadata = img.profile\n",
    "metadata['count'] = 41\n",
    "\n",
    "# write your new raster\n",
    "with rasterio.open(here(\"./data/intermediate/PET/PET_rolling_avg_OGres.tif\"), 'w', **metadata) as dst:\n",
    "    dst.write(newarray)\n",
    "    \n",
    "# now use resample this array to the CA_grid resolution. See https://stackoverflow.com/questions/10454316/how-to-project-and-resample-a-grid-to-match-another-grid-with-gdal-python\n",
    "\n",
    "# Source\n",
    "src_filename = str(here(\"./data/intermediate/PET/PET_rolling_avg_OGres.tif\"))\n",
    "src = gdal.Open(src_filename, gdalconst.GA_ReadOnly)\n",
    "src_proj = src.GetProjection()\n",
    "src_geotrans = src.GetGeoTransform()\n",
    "\n",
    "# We want a section of source that matches this:\n",
    "match_filename = str(here(\"./data/intermediate/CA_grid.tif\"))\n",
    "match_ds = gdal.Open(match_filename, gdalconst.GA_ReadOnly)\n",
    "match_proj = match_ds.GetProjection()\n",
    "match_geotrans = match_ds.GetGeoTransform()\n",
    "wide = match_ds.RasterXSize\n",
    "high = match_ds.RasterYSize\n",
    "\n",
    "# Output / destination\n",
    "dst_filename = str(here(\"./data/intermediate/PET/PET_rolling_avg.tif\"))\n",
    "dst = gdal.GetDriverByName('GTiff').Create(dst_filename, wide, high, 41, gdalconst.GDT_Float32)\n",
    "dst.SetGeoTransform( match_geotrans )\n",
    "dst.SetProjection( match_proj)\n",
    "\n",
    "# Do the work\n",
    "gdal.ReprojectImage(src, dst, src_proj, match_proj, gdalconst.GRA_Bilinear)\n",
    "\n",
    "del dst # Flush\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600b5018-fd88-4f98-bd75-caf96a3aafdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
