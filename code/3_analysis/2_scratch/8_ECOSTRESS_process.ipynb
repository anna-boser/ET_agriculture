{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26cf6e58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This file makes ET averages for the time intervals. \n",
    "# Note that randomness would need to be inserted before this step in order to bootstrap. \n",
    "\n",
    "# Anna Boser November 5, 2021\n",
    "\n",
    "from pyprojroot import here\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time\n",
    "from osgeo import gdal#, gdalconst\n",
    "import matplotlib.pyplot as plt\n",
    "# from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89a62b3-ae51-4df3-8d9f-88af36c22d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.75860500335693\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "img = gdal.Open(str(here(\"./data/intermediate/ECOSTRESS/ETinst_OGunits_1.tif\")))\n",
    "array = img.ReadAsArray() #date lon lat\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "852da506-b857-4076-96ee-6a7c86acf57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(array.shape) #date lon lat\n",
    "# print(np.amax(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e1e24d5-8be7-4721-8223-3ac2a25560df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5, 6): # should be 2,20 for in cluster\n",
    "    img = gdal.Open(str(here(\"./data/intermediate/ECOSTRESS/ETinst_OGunits_{}.tif\".format(i))))\n",
    "    a = img.ReadAsArray()\n",
    "    array = np.concatenate([array, a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0edf65d7-ccca-4f74-b81c-af512da762be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 15017, 16289)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3ef9b9a-c267-4eb3-a6ed-06c84289a987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 15017, 16289)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array[array < -20] = np.NaN # NaN values are a very large negative number. I leave room for some negative values in case of condensation\n",
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "582ac9bb-7a47-4ca9-b072-31778f91c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00c8e83f-ecff-4e83-8268-c320c9c847b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dates\n",
    "date_list = pd.read_csv(here(\"./data/intermediate/ECOSTRESS/dates.csv\"))['x'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360aab2b-9241-42ba-a95c-2f9b49a6abbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.to_datetime(date_list).to_list()\n",
    "# date_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67b3ce67-49c6-4824-a843-e2019b922104",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_list = [datetime.datetime.strptime(d, \"%Y-%m-%d\").date() for d in date_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3c4db6c-63f0-484d-a9b9-fd99e0ae8ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_list[1]\n",
    "date_list = date_list[0:50] + date_list[250:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4323916-967c-42a8-b1dc-a30bca7fb758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to do that thing where I take the first 14 days of the year and put it at the end of the year \n",
    "imgs_2019 = array[[d.year==2019 for d in date_list]]\n",
    "imgs_2020 = array[[d.year==2020 for d in date_list]]\n",
    "\n",
    "date_array = np.array(date_list)\n",
    "dates_2019 = date_array[[d.year==2019 for d in date_list]]\n",
    "dates_2020 = date_array[[d.year==2020 for d in date_list]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98dd0cf0-f6fc-4c1d-8f7b-d9533578cb71",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-91a2e9f6248d>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-91a2e9f6248d>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    d_19_to_20 = np.array([d.year=2020 for d in d_19_to_20])\u001b[0m\n\u001b[0m                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d_19_to_20 = dates_2019[[d < datetime.date(day = 15, month = 1, year = 2019) for d in dates_2019]]\n",
    "d_19_to_20 = np.array([d.replace(year = 2020) for d in d_19_to_20])\n",
    "d_20_to_21 = dates_2020[[d < datetime.date(day = 15, month = 1, year = 2020) for d in dates_2020]]\n",
    "d_20_to_21 = np.array([d.replace(year = 2021) for d in d_20_to_21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ae92e-4058-469a-868f-e4c1e93312cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_2019 = np.concatenate([imgs_2019[[d >= datetime.date(day = 15, month = 1, year = 2019) for d in dates_2019]], imgs_2019[[d < datetime.date(day = 15, month = 1, year = 2019) for d in dates_2019]]])\n",
    "imgs_2020 = np.concatenate([imgs_2020[[d >= datetime.date(day = 15, month = 1, year = 2020) for d in dates_2020]], imgs_2020[[d < datetime.date(day = 15, month = 1, year = 2020) for d in dates_2020]]])\n",
    "\n",
    "dates_2019 = np.concatenate([dates_2019[[d >= datetime.date(day = 15, month = 1, year = 2019) for d in dates_2019]], d_19_to_20])\n",
    "dates_2020 = np.concatenate([dates_2020[[d >= datetime.date(day = 15, month = 1, year = 2020) for d in dates_2020]], d_20_to_21])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63845c7f-13f5-43d1-bdc7-e693b830547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.concatenate([imgs_2019, imgs_2020])\n",
    "\n",
    "date_list = np.concatenate([dates_2019, dates_2020])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a3cc78e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2019-01-27',\n",
       " '2019-01-28',\n",
       " '2019-01-28',\n",
       " '2019-01-29',\n",
       " '2019-01-29',\n",
       " '2019-01-29',\n",
       " '2019-02-01',\n",
       " '2019-02-02',\n",
       " '2019-05-30',\n",
       " '2019-05-31']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average by time interval\n",
    "\n",
    "# these are the start dates of the wanted time intervals\n",
    "date_starts = [datetime.date(day = 15, month = m, year = y) for y in range(2019,2021) for m in [1,3,5,7,9,11]]\n",
    "del date_starts[1]\n",
    "\n",
    "# index of image on or nearest after start date\n",
    "start_index = [date_list.index(min([i for i in date_list if i >= date_start], key=lambda x:x-date_start)) + 1 for date_start in date_starts] # plus one since bands are 1 indexed\n",
    "\n",
    "# index of image on or nearest previous to start date + 61 days (this is for a non-inclusive index range so this date will be the first one not to be included in a subset)\n",
    "end_index = [date_list.index(min([i for i in date_list if i <= date_start + datetime.timedelta(days=61)], key=lambda x:date_start+datetime.timedelta(days=61)-x)) + 1 for date_start in date_starts] # plus one since bands are 1 indexed\n",
    "\n",
    "#average by time interval\n",
    "newarray = np.stack([array[start_index[i]:end_index[i]].mean(axis = 0) for i in range(0,len(start_index))], axis=0)\n",
    "newarray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a19fa26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "\n",
    "# get metadata\n",
    "metadata = img.profile\n",
    "metadata['count'] = 41 # 41 different time intervals\n",
    "\n",
    "# write your new raster\n",
    "with rasterio.open(here(\"./data/intermediate/ECOSTRESS/ETinst_rolling_average.tif\"), 'w', **metadata) as dst:\n",
    "    dst.write(newarray)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
